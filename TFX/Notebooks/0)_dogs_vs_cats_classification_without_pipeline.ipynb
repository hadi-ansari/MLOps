{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hadi-ansari/MLOps/blob/main/TFX/Notebooks/0)_dogs_vs_cats_classification_without_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A tutorial for training a model using cats & dogs dataset\n",
        "\n",
        "In this notebook-based tutorial, we will create and run a ML model for a cats vs dogs classification. This model is not implemented inside a TFX pipeline and is a standalone code."
      ],
      "metadata": {
        "id": "pBDpiOH6bfjs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gi_jMKM_DxmS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load you kaggle api key"
      ],
      "metadata": {
        "id": "E0pyBlDosljE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "OxcjPkjSEqIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the dataset\n",
        "This will the install kaggle cli and download the dataset from kaggle."
      ],
      "metadata": {
        "id": "IJWLB7C8stas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "'chmod 600 /root/.kaggle/kaggle.json'\n",
        "!kaggle datasets download -d salader/dogs-vs-cats\n",
        "!unzip dogs-vs-cats.zip\n",
        "!rm -rf test train dogs-vs-cats.zip"
      ],
      "metadata": {
        "id": "W_o8fvVhEzeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run this reduce the size of dataset\n",
        "It might take a very long time to train the model or troubleshoot the code if the size of the dataset is too big."
      ],
      "metadata": {
        "id": "1WHyfJba8vaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -1 dogs_vs_cats/train/dogs/* | tail -n +501 | xargs rm \n",
        "!ls -1 dogs_vs_cats/train/cats/* | tail -n +501 | xargs rm\n",
        "\n",
        "!ls -1 dogs_vs_cats/test/dogs/* | tail -n +151 | xargs rm \n",
        "!ls -1 dogs_vs_cats/test/cats/* | tail -n +151 | xargs rm "
      ],
      "metadata": {
        "id": "DSiQpveIE5XI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variable definition"
      ],
      "metadata": {
        "id": "q5OFKSrZtfBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 3\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "metadata": {
        "id": "g2acGz2-Eapm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment\n",
        "This is just to test how to load an image and resize it. It has nothing to do with the training code."
      ],
      "metadata": {
        "id": "48w2HUTK8YbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "temp_image = cv2.imread(\"/content/dogs_vs_cats/train/cats/cat.10003.jpg\")\n",
        "temp_image = cv2.cvtColor(temp_image, cv2.COLOR_BGR2RGB)\n",
        "temp_image = temp_image/255.0\n",
        "temp_gray_image = tf.image.rgb_to_grayscale(temp_image)\n",
        "temp_gray_image = tf.squeeze(temp_gray_image, axis=-1)\n",
        "temp_image = tf.image.resize_with_pad(temp_image, target_height=100, target_width=100)\n",
        "print(temp_image.shape)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(temp_image)\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LvzJZx0TYc30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert image dataset to TFRecords\n",
        "\n",
        "We followed the instructions according [this](https://ai.plainenglish.io/a-quick-and-simple-guide-to-tfrecord-c421337a6562).\n"
      ],
      "metadata": {
        "id": "EmrVuxadtq2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import random\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data_root=\"dogs_vs_cats\"\n",
        "\n",
        "# Setup the train and test imgage directories\n",
        "train_dir = os.path.join(data_root, \"train\")\n",
        "test_dir = os.path.join(data_root, \"test\")\n",
        "\n",
        "# setup train and test TFRecord files\n",
        "train_tfrecord='train_data.tfrecords'\n",
        "test_tfrecord = 'test_data.tfrecords'\n",
        "\n",
        "# Define the name of folders of each class\n",
        "# We only have two classes in this case.\n",
        "folders=['dogs', 'cats']\n",
        "\n",
        "# List all train and test image path\n",
        "train_image_path=[]\n",
        "test_image_path=[]\n",
        "\n",
        "for i in range(len(folders)):\n",
        "    for file in os.listdir(os.path.join(train_dir, folders[i])):\n",
        "        train_image_path.append(os.path.join(train_dir, folders[i], file))\n",
        "    for file in os.listdir(os.path.join(test_dir, folders[i])):\n",
        "        test_image_path.append( os.path.join(test_dir, folders[i], file))\n",
        "\n",
        "\n",
        "print(\"Number of train images found: \", len(train_image_path))\n",
        "print(\"Number of test images found: \", len(test_image_path))\n",
        "\n",
        "# Shuffle the image paths for better accuracy and precision\n",
        "random.seed(0)\n",
        "random.shuffle(train_image_path)\n",
        "random.shuffle(test_image_path)\n",
        "\n",
        "# create train and test lables for shuffled image paths\n",
        "# 0 for cat and 1 for dog\n",
        "train_labels=[]\n",
        "test_labels=[]\n",
        "for i in range(len(train_image_path)):\n",
        "    if os.path.basename(train_image_path[i])[:3]=='cat':\n",
        "        train_labels.append(0)\n",
        "    else:\n",
        "        train_labels.append(1)\n",
        "\n",
        "for i in range(len(test_image_path)):\n",
        "    if os.path.basename(test_image_path[i])[:3]=='cat':\n",
        "        test_labels.append(0)\n",
        "    else:\n",
        "        test_labels.append(1)\n",
        "\n",
        "# The following functions can be used to convert a value to a type compatible\n",
        "# with tf.train.Example.\n",
        "\n",
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def serialize_example(image_string, label):\n",
        "    ## Create a dictionary with features for images and their target labels\n",
        "    image_shape = tf.io.decode_jpeg(image_string).shape\n",
        "\n",
        "    feature = {\n",
        "      'label': _int64_feature(label),\n",
        "      'image_raw': _bytes_feature(image_string),\n",
        "    }\n",
        "    #  Create a Features message using tf.train.Example.\n",
        "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "    #serializes the message and returns it as a string. Note that the bytes are binary\n",
        "    return example_proto.SerializeToString()\n",
        "\n",
        "def write_TFRecord(image_path, label):\n",
        "    image_string = open(image_path, 'rb').read()\n",
        "    example = serialize_example(image_string, label)\n",
        "    return example\n",
        "\n",
        "#Write Train TFRecord file\n",
        "with tf.io.TFRecordWriter(train_tfrecord) as writer:\n",
        "    for image_path, label in zip(train_image_path, train_labels):\n",
        "        writer.write(write_TFRecord(image_path, int(label)))\n",
        "\n",
        "#Write Test TFRecord file\n",
        "with tf.io.TFRecordWriter(test_tfrecord) as writer:\n",
        "    for image_path, label in zip(test_image_path, test_labels):\n",
        "         writer.write(write_TFRecord(image_path, int(label)))"
      ],
      "metadata": {
        "id": "Jps3kU6cTxTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Restructure the files\n",
        "This commands restructure the files and create a directory named `dataset` and move the TFRecord files into `dataset/train` and `dataset/test`."
      ],
      "metadata": {
        "id": "MX9o7yRwuDi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf dataset\n",
        "!mkdir dataset\n",
        "!mkdir dataset/train\n",
        "!mkdir dataset/test\n",
        "!mv train_data.tfrecords dataset/train\n",
        "!mv test_data.tfrecords dataset/test"
      ],
      "metadata": {
        "id": "y-njCLy8UE4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The old way of loading the dataset\n",
        "Run this if you want to load the dataset from directories in **JPEG** format."
      ],
      "metadata": {
        "id": "yDGkr09vNcQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"./dogs_vs_cats/train\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    batch_size=32,\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "eval_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"./dogs_vs_cats/test\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    batch_size=32,\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    shuffle=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "4VclZXW8Ee7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The newer way of loading the dataset\n",
        "Run this if you want to load the dataset stored in **TFRecord** format."
      ],
      "metadata": {
        "id": "TgIZTK_HffPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the feature description of your tfrecord dataset\n",
        "feature_description = {\n",
        "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
        "}\n",
        "# Define a function to parse the tfrecord dataset\n",
        "def _parse_function_old(example_proto):\n",
        "    # Parse the input `tf.train.Example` proto using the feature description\n",
        "    features = tf.io.parse_single_example(example_proto, feature_description)\n",
        "    return features\n",
        "\n",
        "# Define a function to parse the tfrecord dataset\n",
        "def _parse_function_new(example_proto):\n",
        "    # Parse the input `tf.train.Example` proto using the feature description\n",
        "    features = tf.io.parse_single_example(example_proto, feature_description)\n",
        "    \n",
        "    # Decode the raw image data\n",
        "    image = tf.io.decode_jpeg(features['image_raw'], channels=3)\n",
        "    # Resize the image\n",
        "    image = tf.image.resize(image, [150, 150])\n",
        "    \n",
        "    # Normalize the pixel values\n",
        "    # image = tf.cast(image, tf.float32) / 255.0\n",
        "    \n",
        "    # Get the label\n",
        "    label = features['label']\n",
        "    \n",
        "    return image, label\n",
        "\n",
        "# Load the train tfrecord dataset\n",
        "train_ds = tf.data.TFRecordDataset('./dataset/train/train_data.tfrecords')\n",
        "train_ds = train_ds.map(_parse_function_new)\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "\n",
        "# Load the test tfrecord dataset\n",
        "eval_ds = tf.data.TFRecordDataset('./dataset/test/test_data.tfrecords')\n",
        "eval_ds = eval_ds.map(_parse_function_new)\n",
        "eval_ds = eval_ds.batch(batch_size)\n"
      ],
      "metadata": {
        "id": "Zkl76B-3je78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write model training code\n",
        "We will create a simple CNN (Convolutional Neural Network) model for cats vs dogs classification using TensorFlow Keras\n",
        "API. This model training code will be saved to a separate file."
      ],
      "metadata": {
        "id": "o2YSpZXC9CSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gzip\n",
        "\n",
        "# Create the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "          loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "          metrics=['accuracy'])\n",
        "\n",
        "# Print a summary of the model\n",
        "model.summary()\n",
        "\n",
        "# Train our model\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    validation_data=eval_ds)\n",
        "\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SQnyjTo6JirV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "f9e3hs8zgC59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probability_model = tf.keras.Sequential([model, \n",
        "                                         tf.keras.layers.Softmax()])\n",
        "\n",
        "\n",
        "predictions = probability_model.predict(eval_ds)"
      ],
      "metadata": {
        "id": "Wq47QprpM0EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the trained model to predict on the eval_ds dataset\n",
        "predictions = model.predict(eval_ds)\n",
        "\n",
        "# Print the predictions for the first 10 images in the dataset\n",
        "for image, prediction in zip(eval_ds.take(10), predictions[:10]):\n",
        "    predicted_label = \"dog\" if prediction > 0.5 else \"cat\"\n",
        "    true_label = \"dog\" if image[1].numpy()[0] == 1 else \"cat\"\n",
        "    print(\"Predicted label: \", predicted_label)\n",
        "    print(\"True label: \", true_label)"
      ],
      "metadata": {
        "id": "Tt3xPSGrk40b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}