{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hadi-ansari/TFX/blob/main/Cat_%26_Dog_recognition_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x1ypzczQCwy"
      },
      "source": [
        "# Simple TFX Pipeline Tutorial using cats & dogs dataset\n",
        "\n",
        "***A pipeline to train a model for recognizing cats and dogs.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VuwrlnvQJ5k"
      },
      "source": [
        "In this notebook-based tutorial, we will create and run a TFX pipeline\n",
        "for a simple classification model.\n",
        "The pipeline will consist of three essential TFX components: ExampleGen,\n",
        "Trainer and Pusher. The pipeline includes the most minimal ML workflow like\n",
        "importing data, training a model and exporting the trained model.\n",
        "\n",
        "Please see\n",
        "[Understanding TFX Pipelines](https://www.tensorflow.org/tfx/guide/understanding_tfx_pipelines)\n",
        "to learn more about various concepts in TFX."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmgi8ZvQkScg"
      },
      "source": [
        "## Set Up\n",
        "We first need to install the TFX Python package and download\n",
        "the dataset which we will use for our model.\n",
        "\n",
        "### Upgrade Pip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as4OTe2ukSqm"
      },
      "source": [
        "!pip install --upgrade pip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyQtljP-qPHY"
      },
      "source": [
        "!pip install -U tfx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uninstall shapely\n",
        "\n",
        "TODO(b/263441833) This is a temporal solution to avoid an\n",
        "ImportError. Ultimately, it should be handled by supporting a\n",
        "recent version of Bigquery, instead of uninstalling other extra\n",
        "dependencies."
      ],
      "metadata": {
        "id": "DCa5Bs00k3ZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall shapely -y"
      ],
      "metadata": {
        "id": "mYn4k-r-k3qN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e74cdef-eeb4-4e4e-d90f-2bdfa16ebc8c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping shapely as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwT0nov5QO1M"
      },
      "source": [
        "### Did you restart the runtime?\n",
        "\n",
        "If you are using Google Colab, the first time that you run\n",
        "the cell above, you must restart the runtime by clicking\n",
        "above \"RESTART RUNTIME\" button or using \"Runtime > Restart\n",
        "runtime ...\" menu. This is because of the way that Colab\n",
        "loads packages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDtLdSkvqPHe"
      },
      "source": [
        "# Necessary imports\n",
        "\n",
        "We also check the TensorFlow and TFX versions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jh7vKSRqPHb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1423441e-d2d2-4aaa-c8f6-d65913536b7a"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "print('TensorFlow version: {}'.format(tf.__version__))\n",
        "from tfx import v1 as tfx\n",
        "print('TFX version: {}'.format(tfx.__version__))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.11.1\n",
            "TFX version: 1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "4601nR9JQaHM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "e7ce330d-d47b-4671-e4bb-5d9fb32ea28f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b33cf51c-ab10-4a6e-ace7-8b59943c917b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b33cf51c-ab10-4a6e-ace7-8b59943c917b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"hadiansari\",\"key\":\"7446b47ad9855c419a91f5878f30a36f\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11J7XiCq6AFP"
      },
      "source": [
        "Because TFX ExampleGen reads inputs from a directory, we need to create a\n",
        "directory and copy dataset to it."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "'chmod 600 /root/.kaggle/kaggle.json'\n",
        "!kaggle datasets download -d salader/dogs-vs-cats\n",
        "!unzip dogs-vs-cats.zip\n",
        "!rm -rf test train dogs-vs-cats.zip"
      ],
      "metadata": {
        "id": "YpC5qjjwQgwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Minimize the size of the dataset (optional)\n",
        "We minimize the size of the dataset by removing the images from both train and test folders. Train images decreas from 10000 images to 50 and test images decreas from 2500 to 10 images to make the process faster (OBS: just for testing)."
      ],
      "metadata": {
        "id": "HiHkto4Jt8k2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -1 dogs_vs_cats/train/dogs/* | tail -n +51 | xargs rm \n",
        "!ls -1 dogs_vs_cats/train/cats/* | tail -n +51 | xargs rm\n",
        "\n",
        "!ls -1 dogs_vs_cats/test/dogs/* | tail -n +11 | xargs rm \n",
        "!ls -1 dogs_vs_cats/test/cats/* | tail -n +11 | xargs rm "
      ],
      "metadata": {
        "id": "Mju0dtqdtuZL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOjDv93eS5xV"
      },
      "source": [
        "### Set up variables\n",
        "\n",
        "There are some variables used to define a pipeline. You can customize these\n",
        "variables as you want. By default all output from the pipeline will be\n",
        "generated under the current directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aES7Hv5QTDK3"
      },
      "source": [
        "_trainer_module_file = 'dogs_vs_cats_trainer.py'\n",
        "\n",
        "data_root ='dogs_vs_cats'\n",
        "train_dir = os.path.join(data_root, 'train')\n",
        "validation_dir = os.path.join(data_root, 'test')\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures\n",
        "\n",
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "\n",
        "IMG_HEIGHT = 200\n",
        "IMG_WIDTH = 200\n",
        "batch_size = 128\n",
        "PIPELINE_NAME = 'dogs_vs_cats_pipeline'\n",
        "PIPELINE_ROOT = os.path.join('pipelines', PIPELINE_NAME)\n",
        "SERVING_MODEL_DIR = os.path.join('serving_model', PIPELINE_NAME)\n",
        "METADATA_PATH = os.path.join('metadata', PIPELINE_NAME, 'cat&dog_md.db')\n",
        "\n",
        "\n",
        "print('total training cat images:', num_cats_tr)\n",
        "print('total training dog images:', num_dogs_tr)\n",
        "print('total validation cat images:', num_cats_val)\n",
        "print('total validation dog images:', num_dogs_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_ee = tf.keras.utils.image_dataset_from_directory(\n",
        "  train_dir,\n",
        "  seed=123,\n",
        "  image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "val_ds_ee = tf.keras.utils.image_dataset_from_directory(\n",
        "  validation_dir,\n",
        "  seed=123,\n",
        "  image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "SIsWkuExhdoC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da4fe427-5688-48f3-8d2b-652e29f535e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100 files belonging to 2 classes.\n",
            "Found 20 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tfx_bsl.tfxio import dataset_options\n",
        "import os\n",
        "\n",
        "def parse_tfrecord(example_proto):\n",
        "    feature_description = {\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
        "    image = tf.image.decode_jpeg(example['image'], channels=3)\n",
        "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
        "    label = example['label']\n",
        "    return image, label\n",
        "\n",
        "train_ds_temp = tf.data.TFRecordDataset(\"/content/pipelines/dogs_vs_cats_pipeline/ImportExampleGen/examples/13/Split-train/*\")\n",
        "val_ds_temp = tf.data.TFRecordDataset(\"/content/pipelines/dogs_vs_cats_pipeline/ImportExampleGen/examples/14222/Split-eval/*\")\n",
        "\n",
        "# Map the parse function to the dataset\n",
        "train_ds_temp = train_ds_temp.map(parse_tfrecord)\n",
        "val_ds_temp = val_ds_temp.map(parse_tfrecord)\n",
        "\n",
        "# Batch and shuffle the dataset\n",
        "train_ds_temp = train_ds_temp.shuffle(buffer_size=10000, seed=123).batch(batch_size)\n",
        "val_ds_temp = val_ds_temp.batch(batch_size)"
      ],
      "metadata": {
        "id": "jfN4f2anLdgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3OkNz3gTLwM"
      },
      "source": [
        "# Conversion of image dataset to TFRecords\n",
        "\n",
        "We followed the instructions according [this](https://ai.plainenglish.io/a-quick-and-simple-guide-to-tfrecord-c421337a6562).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing required libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "sess = tf.compat.v1.Session(config=config)\n",
        "# Setup the train and test imgage directories\n",
        "train_dir = os.path.join(data_root, \"train\")\n",
        "test_dir = os.path.join(data_root, \"test\")\n",
        "\n",
        "# setup train and test TFRecord file\n",
        "train_tfrecord='train_data.tfrecords'\n",
        "test_tfrecord = 'test_data.tfrecords'\n",
        "\n",
        "# Define the name of folders of each class\n",
        "# We only have two classes in this case.\n",
        "folders=['dogs', 'cats']\n",
        "\n",
        "#List all train and test image path\n",
        "train_image_path=[]\n",
        "test_image_path=[]\n",
        "\n",
        "for i in range(len(folders)):\n",
        "    for file in os.listdir(os.path.join(train_dir, folders[i])):\n",
        "        train_image_path.append(os.path.join(train_dir, folders[i], file))\n",
        "    for file in os.listdir(os.path.join(test_dir, folders[i])):\n",
        "        test_image_path.append( os.path.join(test_dir, folders[i], file))\n",
        "\n",
        "\n",
        "print(\"Number of train images found: \", len(train_image_path))\n",
        "print(\"Number of test images found: \", len(test_image_path))\n",
        "\n",
        "#Shuffle the image paths for better accuracy and precision\n",
        "random.seed(0)\n",
        "random.shuffle(train_image_path)\n",
        "random.shuffle(test_image_path)\n",
        "\n",
        "# create train and test lables for shuffled image paths\n",
        "# 0 for cat and 1 for dog\n",
        "train_labels=[]\n",
        "test_labels=[]\n",
        "for i in range(len(train_image_path)):\n",
        "    if os.path.basename(train_image_path[i])[:3]=='cat':\n",
        "        train_labels.append(0)\n",
        "    else:\n",
        "        train_labels.append(1)\n",
        "\n",
        "for i in range(len(test_image_path)):\n",
        "    if os.path.basename(test_image_path[i])[:3]=='cat':\n",
        "        test_labels.append(0)\n",
        "    else:\n",
        "        test_labels.append(1)\n",
        "\n",
        "def _bytes_feature(value):\n",
        "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"    \n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "        value = value.numpy()\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "def _int64_feature(value):\n",
        "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "def _float_feature(value):\n",
        "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "\n",
        "def serialize_example(image, label):\n",
        "    ## Create a dictionary with features for images and their target labels\n",
        "    feature = {\n",
        "        'image': _bytes_feature(image),\n",
        "        'label': _int64_feature(label), \n",
        "    }\n",
        "    #  Create a Features message using tf.train.Example.\n",
        "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "    #serializes the message and returns it as a string. Note that the bytes are binary\n",
        "    return example_proto.SerializeToString()\n",
        "\n",
        "\n",
        "def write_TFRecord(image_path, label):\n",
        "    img=tf.keras.preprocessing.image.load_img(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH))        \n",
        "    img_array= tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_bytes= tf.io.serialize_tensor(img_array)\n",
        "    example= serialize_example(img_bytes, label)\n",
        "    return example\n",
        "#Write Train TFRecord file\n",
        "with tf.io.TFRecordWriter(train_tfrecord) as writer:\n",
        "    for image_path, label in zip(train_image_path, train_labels):\n",
        "        writer.write(write_TFRecord(image_path, int(label)))\n",
        "#Write Test TFRecord file\n",
        "with tf.io.TFRecordWriter(test_tfrecord) as writer:\n",
        "    for image_path, label in zip(test_image_path, test_labels):\n",
        "         writer.write(write_TFRecord(image_path, int(label)))"
      ],
      "metadata": {
        "id": "BN00rTsiyvV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf74b53d-3386-4ed7-843a-47cd6aa03711"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train images found:  100\n",
            "Number of test images found:  20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf dataset\n",
        "!mkdir dataset\n",
        "!mkdir dataset/train\n",
        "!mkdir dataset/test\n",
        "!mv train_data.tfrecords dataset/train\n",
        "!mv test_data.tfrecords dataset/test"
      ],
      "metadata": {
        "id": "VXBCczk-wx_N"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write model training code\n",
        "\n",
        "We will create a simple DNN model for cats vs dogs classification using TensorFlow Keras\n",
        "API. This model training code will be saved to a separate file.\n",
        "\n",
        "For model training code we found this tutorial on Kaggle\n",
        "[here](https://www.kaggle.com/code/alpaca0984/dogs-vs-cats-tensorflow-2-0-on-google-colab). You need to write a Python file\n",
        "containing `run_fn` function, which is the entrypoint for the `Trainer`\n",
        "component."
      ],
      "metadata": {
        "id": "l0AbWurTgUSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pipeline Definition\n",
        "We define the ML pipeline here. The components of the pipeline are: ImportExampleGen for ingesting the images into the pipeline, Trainer for training the model and Pusher component for serving the model into production environment.\n",
        "\n",
        "For ingesting the image dataset into the pipeline, we got help from this github repository [github](https://github.com/tensorflow/tfx/blob/master/tfx/examples/cifar10/cifar10_pipeline_native_keras.py)"
      ],
      "metadata": {
        "id": "AX5ocD1FYI_H"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M49yYVNBTPd4"
      },
      "source": [
        "from tfx.components.example_gen.component import FileBasedExampleGen\n",
        "from tfx.dsl.components.base import executor_spec\n",
        "from tfx.components.example_gen.csv_example_gen import executor\n",
        "from tfx.dsl.components.base.base_executor import BaseExecutor\n",
        "from tfx.proto import example_gen_pb2\n",
        "from tfx.components import ImportExampleGen\n",
        "from tfx.proto import trainer_pb2\n",
        "\n",
        "\n",
        "def _create_pipeline(pipeline_name: str, pipeline_root: str,\n",
        "                     module_file: str, serving_model_dir: str,\n",
        "                     metadata_path: str) -> tfx.dsl.Pipeline:\n",
        "  print(\"Pipeline creation is running...\\n\\n\\n\")\n",
        "\n",
        "  \"\"\"Creates a three component penguin pipeline with TFX.\"\"\"\n",
        " \n",
        "  input_config = example_gen_pb2.Input(splits=[\n",
        "      example_gen_pb2.Input.Split(name='train', pattern='train/*'),\n",
        "      example_gen_pb2.Input.Split(name='eval', pattern='test/*')\n",
        "  ])\n",
        "\n",
        "  # Brings data into the pipeline.\n",
        "  example_gen = ImportExampleGen(\n",
        "      input_base='/content/dataset', input_config=input_config)\n",
        "  \n",
        "\n",
        "  # Uses user-provided Python function that trains a model.\n",
        "  trainer = tfx.components.Trainer(\n",
        "      module_file=module_file,\n",
        "      examples=example_gen.outputs['examples'],\n",
        "      train_args=tfx.proto.TrainArgs(num_steps=100),\n",
        "      eval_args=tfx.proto.EvalArgs(num_steps=5))\n",
        "\n",
        "  # Pushes the model to a filesystem destination.\n",
        "  pusher = tfx.components.Pusher(\n",
        "      model=trainer.outputs['model'],\n",
        "      push_destination=tfx.proto.PushDestination(\n",
        "          filesystem=tfx.proto.PushDestination.Filesystem(\n",
        "              base_directory=serving_model_dir)))\n",
        "\n",
        "  # Following three components will be included in the pipeline.\n",
        "  components = [\n",
        "      example_gen,\n",
        "      trainer,\n",
        "      #pusher,\n",
        "  ]\n",
        "\n",
        "  return tfx.dsl.Pipeline(\n",
        "      pipeline_name=pipeline_name,\n",
        "      pipeline_root=pipeline_root,\n",
        "      metadata_connection_config=tfx.orchestration.metadata\n",
        "      .sqlite_metadata_connection_config(metadata_path),\n",
        "      components=components)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gnc67uQNTDfW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7bd2426-7ef5-4e8e-b116-0a80f17de3e7"
      },
      "source": [
        "%%writefile {_trainer_module_file}\n",
        "\n",
        "import tensorflow as tf\n",
        "from tfx import v1 as tfx\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_transform as tft\n",
        "from tfx_bsl.tfxio import dataset_options\n",
        "import os\n",
        "import gzip\n",
        "from typing import List\n",
        "from tensorflow_metadata.proto.v0 import schema_pb2\n",
        "from tfx import v1 as tfx\n",
        "from tfx_bsl.public import tfxio\n",
        "from tensorflow_transform.tf_metadata import schema_utils\n",
        "\n",
        "\n",
        "_LABEL_KEY = 'label'\n",
        "IMG_HEIGHT = 200\n",
        "IMG_WIDTH = 200\n",
        "batch_size = 128\n",
        "_FEATURE_SPEC = {\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "        }\n",
        "\n",
        "def _transformed_name(key):\n",
        "  return key + '_xf'\n",
        "\n",
        "def parse_tfrecord(example_proto):\n",
        "    feature_description = {\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
        "    image = tf.image.decode_jpeg(example['image'], channels=3)\n",
        "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
        "    label = example['label']\n",
        "    return image, label\n",
        "\n",
        "def _input_fn(file_pattern: List[str],\n",
        "              data_accessor: tfx.components.DataAccessor,\n",
        "              schema: schema_pb2.Schema,\n",
        "              batch_size: int = 200) -> tf.data.Dataset:\n",
        "  \"\"\"Generates features and label for training.\n",
        "\n",
        "  Args:\n",
        "    file_pattern: List of paths or patterns of input tfrecord files.\n",
        "    data_accessor: DataAccessor for converting input to RecordBatch.\n",
        "    schema: schema of the input data.\n",
        "    batch_size: representing the number of consecutive elements of returned\n",
        "      dataset to combine in a single batch\n",
        "\n",
        "  Returns:\n",
        "    A dataset that contains (features, indices) tuple where features is a\n",
        "      dictionary of Tensors, and indices is a single Tensor of label indices.\n",
        "  \"\"\"\n",
        "  return data_accessor.tf_dataset_factory(\n",
        "      file_pattern,\n",
        "      tfxio.TensorFlowDatasetOptions(\n",
        "          batch_size=batch_size, label_key=_LABEL_KEY),\n",
        "      schema=schema).repeat()\n",
        "\n",
        "\n",
        "# TFX Trainer will call this function.\n",
        "def run_fn(fn_args: tfx.components.FnArgs):\n",
        "  \n",
        "    epochs = 10\n",
        "\n",
        "    # Create the model\n",
        "    model = tf.keras.models.Sequential([\n",
        "        # tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "        # tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "        # tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "        # tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "        # tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "        # tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "        # tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "        # tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "        # tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "        # tf.keras.layers.Flatten(),\n",
        "        # tf.keras.layers.Dense(256, activation='relu'),\n",
        "        # tf.keras.layers.Dropout(0.5),\n",
        "        # tf.keras.layers.Dense(256, activation='relu'),\n",
        "        # tf.keras.layers.Dropout(0.5),\n",
        "        # tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    # Print a summary of the model\n",
        "    model.summary()\n",
        "\n",
        "    # tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n",
        "\n",
        "    # train_ds = fn_args.data_accessor.tf_dataset_factory(\n",
        "    #     fn_args.train_files,\n",
        "    #     dataset_options.TensorFlowDatasetOptions(\n",
        "    #         batch_size=batch_size, label_key=_transformed_name(_LABEL_KEY)),\n",
        "    #     tf_transform_output.transformed_metadata.schema)\n",
        "\n",
        "    # eval_ds = fn_args.data_accessor.tf_dataset_factory(\n",
        "    #     fn_args.eval_files,\n",
        "    #     dataset_options.TensorFlowDatasetOptions(\n",
        "    #         batch_size=batch_size, label_key=_transformed_name(_LABEL_KEY)),\n",
        "    #     tf_transform_output.transformed_metadata.schema)\n",
        "\n",
        "    print(\"\\n\\n\\n HERE => \", fn_args.train_files)\n",
        "    # Load the training dataset\n",
        "    schema = schema_utils.schema_from_feature_spec(_FEATURE_SPEC)\n",
        "\n",
        "    train_ds = _input_fn(\n",
        "        fn_args.train_files,\n",
        "        fn_args.data_accessor,\n",
        "        schema,\n",
        "        batch_size=batch_size)\n",
        "    eval_ds = _input_fn(\n",
        "        fn_args.eval_files,\n",
        "        fn_args.data_accessor,\n",
        "        schema,\n",
        "        batch_size=batch_size)\n",
        "\n",
        "    # Train our model\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        epochs=epochs,\n",
        "        validation_data=eval_ds,\n",
        "        steps_per_epoch=1000\n",
        "    )\n",
        "\n",
        "\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs_range = range(epochs)\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Training Loss')\n",
        "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.show()\n",
        "\n",
        "    # The result of the training should be saved in `fn_args.serving_model_dir`\n",
        "    # directory.\n",
        "    model.save(fn_args.serving_model_dir, save_format='tf')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing {_trainer_module_file}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJbq07THU2GV"
      },
      "source": [
        "## Run the pipeline\n",
        "\n",
        "TFX supports multiple orchestrators to run pipelines.\n",
        "In this tutorial we will use `LocalDagRunner` which is included in the TFX\n",
        "Python package and runs pipelines on local environment.\n",
        "We often call TFX pipelines \"DAGs\" which stands for directed acyclic graph.\n",
        "\n",
        "`LocalDagRunner` provides fast iterations for development and debugging.\n",
        "TFX also supports other orchestrators including Kubeflow Pipelines and Apache\n",
        "Airflow which are suitable for production use cases.\n",
        "\n",
        "See\n",
        "[TFX on Cloud AI Platform Pipelines](https://www.tensorflow.org/tfx/tutorials/tfx/cloud-ai-platform-pipelines)\n",
        "or\n",
        "[TFX Airflow Tutorial](https://www.tensorflow.org/tfx/tutorials/tfx/airflow_workshop)\n",
        "to learn more about other orchestration systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mp0AkmrPdUb"
      },
      "source": [
        "Now we create a `LocalDagRunner` and pass a `Pipeline` object created from the\n",
        "function we already defined.\n",
        "\n",
        "The pipeline runs directly and you can see logs for the progress of the pipeline including ML model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAtfOZTYWJu-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5f416d4e-f85e-4875-89e9-d983a8002607"
      },
      "source": [
        "tfx.orchestration.LocalDagRunner().run(\n",
        "  _create_pipeline(\n",
        "      pipeline_name=PIPELINE_NAME,\n",
        "      pipeline_root=PIPELINE_ROOT,\n",
        "      module_file=_trainer_module_file,\n",
        "      serving_model_dir=SERVING_MODEL_DIR,\n",
        "      metadata_path=METADATA_PATH))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline creation is running...\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_68 (Conv2D)          (None, 198, 198, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_38 (MaxPoolin  (None, 99, 99, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_69 (Conv2D)          (None, 97, 97, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_39 (MaxPoolin  (None, 48, 48, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_70 (Conv2D)          (None, 46, 46, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_40 (MaxPoolin  (None, 23, 23, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_71 (Conv2D)          (None, 21, 21, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_41 (MaxPoolin  (None, 10, 10, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 12800)             0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 512)               6554112   \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,795,457\n",
            "Trainable params: 6,795,457\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            " HERE =>  ['pipelines/dogs_vs_cats_pipeline/ImportExampleGen/examples/29/Split-train/*']\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_68 (Conv2D)          (None, 198, 198, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_38 (MaxPoolin  (None, 99, 99, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_69 (Conv2D)          (None, 97, 97, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_39 (MaxPoolin  (None, 48, 48, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_70 (Conv2D)          (None, 46, 46, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_40 (MaxPoolin  (None, 23, 23, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_71 (Conv2D)          (None, 21, 21, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_41 (MaxPoolin  (None, 10, 10, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 12800)             0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 512)               6554112   \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,795,457\n",
            "Trainable params: 6,795,457\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:absl:Execution 30 failed.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-1aba6b1efff0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m tfx.orchestration.LocalDagRunner().run(\n\u001b[0m\u001b[1;32m      2\u001b[0m   _create_pipeline(\n\u001b[1;32m      3\u001b[0m       \u001b[0mpipeline_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIPELINE_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mpipeline_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIPELINE_ROOT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mmodule_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_trainer_module_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tfx/orchestration/portable/tfx_runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, pipeline, run_options, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m       \u001b[0mrun_options_pb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_with_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_pb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_options_pb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tfx/orchestration/local/local_dag_runner.py\u001b[0m in \u001b[0;36mrun_with_ir\u001b[0;34m(self, pipeline, run_options)\u001b[0m\n\u001b[1;32m    107\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection_config\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmlmd_handle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mpartial_run_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnapshot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlmd_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mcomponent_launcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Component %s is finished.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tfx/orchestration/portable/launcher.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    571\u001b[0m               executor_watcher.address)\n\u001b[1;32m    572\u001b[0m           \u001b[0mexecutor_watcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mexecutor_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_executor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         execution_output = (\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tfx/orchestration/portable/launcher.py\u001b[0m in \u001b[0;36m_run_executor\u001b[0;34m(self, execution_info)\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0moutputs_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_output_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m       \u001b[0mexecutor_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executor_operator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_executor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m       \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tfx/orchestration/portable/python_executor_operator.py\u001b[0m in \u001b[0;36mrun_executor\u001b[0;34m(self, execution_info)\u001b[0m\n\u001b[1;32m    133\u001b[0m         pipeline_run_id=execution_info.pipeline_run_id)\n\u001b[1;32m    134\u001b[0m     \u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executor_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrun_with_executor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tfx/orchestration/portable/python_executor_operator.py\u001b[0m in \u001b[0;36mrun_with_executor\u001b[0;34m(execution_info, executor)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   result = executor.Do(execution_info.input_dict, output_dict,\n\u001b[0m\u001b[1;32m     59\u001b[0m                        execution_info.exec_properties)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tfx/components/trainer/executor.py\u001b[0m in \u001b[0;36mDo\u001b[0;34m(self, input_dict, output_dict, exec_properties)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mabsl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training model.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0mrun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;31m# Note: If trained with multi-node distribution workers, it is the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/dogs_vs_cats_trainer.py\u001b[0m in \u001b[0;36mrun_fn\u001b[0;34m(fn_args)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;31m# Train our model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     history = model.fit(\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/input_spec.py\", line 197, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Missing data for input \"conv2d_68_input\". You passed a data dictionary with keys ['image']. Expected the following keys: ['conv2d_68_input']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppERq0Mj6xvW"
      },
      "source": [
        "You should see \"INFO:absl:Component Pusher is finished.\" at the end of the\n",
        "logs if the pipeline finished successfully. Because `Pusher` component is the\n",
        "last component of the pipeline.\n",
        "\n",
        "The pusher component pushes the trained model to the `SERVING_MODEL_DIR` which\n",
        "is the `serving_model/penguin-simple` directory if you did not change the\n",
        "variables in the previous steps. You can see the result from the file browser\n",
        "in the left-side panel in Colab, or using the following command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTHROkqX6yHx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "114d8a19-bd54-4573-f80f-d63791816cdc"
      },
      "source": [
        "# List files in created model directory.\n",
        "!find {SERVING_MODEL_DIR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "find: serving_models/cat: No such file or directory\n",
            "/bin/bash: dog_pipeline: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08R8qvweThRf"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "You can find more resources on https://www.tensorflow.org/tfx/tutorials.\n",
        "\n",
        "Please see\n",
        "[Understanding TFX Pipelines](https://www.tensorflow.org/tfx/guide/understanding_tfx_pipelines)\n",
        "to learn more about various concepts in TFX.\n"
      ]
    }
  ]
}