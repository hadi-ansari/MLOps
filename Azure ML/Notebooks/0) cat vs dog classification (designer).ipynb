{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Azure ML Pipeline Tutorial using Designer and MPI components\n",
        "\n",
        "In this notebook-based tutorial, we will create and run a Azure ML pipeline\n",
        "for a simple cats vs dogs classification model.\n",
        "The pipeline will consist of the following essential components which:\n",
        "- Convert to Image Directory (Designer component)\n",
        "- Init Image Transformation (Designer component)\n",
        "- Apply Image Transformation (Designer component)\n",
        "- Train Image Classification (MPI custom component)\n",
        "\n",
        "We followed this Azure ML [tutorial](https://github.com/Azure/azureml-examples/blob/main/sdk/python/jobs/pipelines/2d_image_classification_with_densenet/image_classification_with_densenet.ipynb)."
      ],
      "metadata": {
        "id": "6x1ypzczQCwy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Up\n",
        "We first need to install the azure-ai-ml and azureml Python packages and download\n",
        "the dataset which we will use for our model."
      ],
      "metadata": {
        "id": "Fmgi8ZvQkScg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azure-ai-ml"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "as4OTe2ukSqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mldesigner"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azureml"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to workspace"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle to the workspace\n",
        "from azure.ai.ml import MLClient, Input\n",
        "\n",
        "# Authentication package\n",
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1684240928218
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=\"<SUBSCRIPTION ID>\",\n",
        "    resource_group_name=\"<RESOURCE GROUP NAME>\",\n",
        "    workspace_name=\"<WORKSPACE NAME>\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1684240929207
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the cat vs dog dataset\n",
        "We use dogs-vs-cats dataset from Kaggle and then read the inputs from a directory. So we need to create a\n",
        "directory and copy dataset to it."
      ],
      "metadata": {
        "id": "11J7XiCq6AFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "'chmod 600 /root/.kaggle/kaggle.json'\n",
        "!kaggle datasets download -d salader/dogs-vs-cats\n",
        "!unzip dogs-vs-cats.zip\n",
        "!rm -rf test train dogs-vs-cats.zip"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1683284409247
        },
        "id": "YpC5qjjwQgwY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reduce size of the dataset (optional)\n",
        "We reduce size of the dataset by removing the images from both train and test folders to speed up the ML process. Train images decreas from 20000 images to 2000 and test images decreas from 5000 to 500 images to make the process faster (OBS: just for testing)."
      ],
      "metadata": {
        "id": "HiHkto4Jt8k2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -1 dogs_vs_cats/train/dogs/* | tail -n +101 | xargs rm \n",
        "!ls -1 dogs_vs_cats/train/cats/* | tail -n +101 | xargs rm\n",
        "\n",
        "!ls -1 dogs_vs_cats/test/dogs/* | tail -n +51 | xargs rm \n",
        "!ls -1 dogs_vs_cats/test/cats/* | tail -n +51 | xargs rm "
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "executionInfo": {
          "elapsed": 2451,
          "status": "ok",
          "timestamp": 1682412352847,
          "user": {
            "displayName": "Hadi Ansari",
            "userId": "13801521134374285736"
          },
          "user_tz": -120
        },
        "id": "Mju0dtqdtuZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a directory for pipeline components"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "components_dir = \"./components\"\n",
        "os.makedirs(components_dir, exist_ok=True)\n",
        "\n",
        "trainer_dir = \"./components/trainer\"\n",
        "os.makedirs(trainer_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1684239977173
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up necessary variables\n",
        "\n",
        "There are some variables used to define a pipeline. You can customize these\n",
        "variables as you want. By default all output from the pipeline will be\n",
        "generated under the current directory."
      ],
      "metadata": {
        "id": "lOjDv93eS5xV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "_components_dir = 'components'\n",
        "_trainer_file = os.path.join(trainer_dir, 'train_component.py')\n",
        "\n",
        "IMG_SIZE = 150 # This refers to the height and width of the images"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1684240933286
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_root ='../datasets/dogs_vs_cats_small'\n",
        "train_dir = os.path.join(data_root, 'train')\n",
        "validation_dir = os.path.join(data_root, 'test')\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures\n",
        "\n",
        "\n",
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "\n",
        "\n",
        "print('total training cat images:', num_cats_tr)\n",
        "print('total training dog images:', num_dogs_tr)\n",
        "print('total validation cat images:', num_cats_val)\n",
        "print('total validation dog images:', num_dogs_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "total training cat images: 102\ntotal training dog images: 100\ntotal validation cat images: 52\ntotal validation dog images: 50\n--\nTotal training images: 202\nTotal validation images: 102\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 447,
          "status": "ok",
          "timestamp": 1682412359044,
          "user": {
            "displayName": "Hadi Ansari",
            "userId": "13801521134374285736"
          },
          "user_tz": -120
        },
        "id": "aES7Hv5QTDK3",
        "outputId": "3a3cee2c-ba29-4be4-809b-8a56dc258596",
        "gather": {
          "logged": 1684240941249
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the component when it is YAML"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import load_component\n",
        "# load component function from yaml\n",
        "convert_to_image = load_component(source=\"components/convert_to_image/convert_to_image_component.yaml\")\n",
        "\n",
        "apply_transform = load_component(\n",
        "    source=\"components/apply_image_transformation/apply_image_transformation.yaml\"\n",
        ")\n",
        "\n",
        "init_transform = load_component(\n",
        "    source=\"components/init_image_transformation/init_image_transformation.yaml\"\n",
        ")\n",
        "\n",
        "# this train component is an mpi component.\n",
        "imagecnn_train = load_component(source=\"components/imagecnn_train/entry.spec.yaml\")"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1684241023368
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the datasets"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = Input(name=\"TrainData\", type=\"uri_file\", path=\"../datasets/dogs_vs_cats_small/train\")\n",
        "test_ds = Input(name=\"TestData\", type=\"uri_file\", path=\"../datasets/dogs_vs_cats_small/test\")\n",
        "\n",
        "\n",
        "# gpu_compute_target = \"gpu-cluster\""
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1684242386213
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline definition"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.dsl import pipeline\n",
        "from azure.ai.ml import load_component\n",
        "# define a pipeline containing 3 nodes: Prepare data node, train node, and score node\n",
        "@pipeline(\n",
        "    default_compute=\"eight-core-hadan326\",\n",
        ")\n",
        "#def cat_vs_dog_classifier():\n",
        "def cat_vs_dog_classifier():\n",
        "    convert_train = convert_to_image(input_path = train_ds)\n",
        "    convert_test = convert_to_image(input_path = test_ds)\n",
        "\n",
        "    init_image_transformation = init_transform(\n",
        "        resize=\"True\",\n",
        "        size=IMG_SIZE,\n",
        "        center_crop=\"False\",\n",
        "        pad=\"False\",\n",
        "        padding=0,\n",
        "        color_jitter=\"False\",\n",
        "        grayscale=\"False\",\n",
        "        random_resized_crop=\"False\",\n",
        "        random_crop=\"False\",\n",
        "        random_horizontal_flip=\"True\",\n",
        "        random_vertical_flip=\"False\",\n",
        "        random_rotation=\"False\",\n",
        "        random_affine=\"False\",\n",
        "        random_grayscale=\"False\",\n",
        "        random_perspective=\"False\",\n",
        "    )\n",
        "\n",
        "    apply_trans_on_train = apply_transform(\n",
        "    mode=\"For training\",\n",
        "    input_image_transform_path=init_image_transformation.outputs.output_path,\n",
        "    input_image_dir_path=convert_train.outputs.output_path,\n",
        "    )\n",
        "\n",
        "    apply_trans_on_val = apply_transform(\n",
        "        mode=\"For inference\",\n",
        "        input_image_transform_path=init_image_transformation.outputs.output_path,\n",
        "        input_image_dir_path=convert_test.outputs.output_path,\n",
        "    )\n",
        "\n",
        "    imagecnn_train_gpu = imagecnn_train(\n",
        "        train_data=apply_trans_on_train.outputs.output_path,\n",
        "        valid_data=apply_trans_on_val.outputs.output_path,\n",
        "        data_backend=\"pytorch\",\n",
        "        arch=\"resnet50\",\n",
        "        model_config=\"classic\",\n",
        "        workers=5,\n",
        "        epochs=4,\n",
        "        batch_size=16,\n",
        "        optimizer_batch_size=-1,\n",
        "        lr=0.1,\n",
        "        lr_schedule=\"step\",\n",
        "        warmup=0,\n",
        "        label_smoothing=0.0,\n",
        "        mixup=0.0,\n",
        "        momentum=0.9,\n",
        "        weight_decay=0.0001,\n",
        "        print_freq=10,\n",
        "        resume=\"\",\n",
        "        pretrained_weights=\"\",\n",
        "        static_loss_scale=1.0,\n",
        "        prof=-1,\n",
        "        seed=123,\n",
        "        raport_file=\"experiment_raport.json\",\n",
        "        save_checkpoint_epochs=2,\n",
        "    )\n",
        "\n",
        "    # It does not work with the GPU of type \"Standard_NC24ads_A100_v4 (24 cores, 220 GB RAM, 64 GB disk)\"\n",
        "    # imagecnn_train_gpu.compute = gpu_compute_target\n",
        "    # imagecnn_train_gpu.resources.instance_count = 1\n",
        "\n",
        "# create a pipeline\n",
        "pipeline_job = cat_vs_dog_classifier()"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1684242388465
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the pipeline job"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline_job, experiment_name=\"dogs_vs_cats_experiment2\"\n",
        ")\n",
        "pipeline_job"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "PipelineJob({'inputs': {}, 'outputs': {}, 'jobs': {}, 'component': PipelineComponent({'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': True, 'name': 'azureml_anonymous', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/eight-core-hadan326/code/Users/Notebooks/dogs_vs_cats_simple_designer_components', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f3bcce62c50>, 'version': '1', 'latest_version': None, 'schema': None, 'type': 'pipeline', 'display_name': 'cat_vs_dog_classifier', 'is_deterministic': None, 'inputs': {}, 'outputs': {}, 'yaml_str': None, 'other_parameter': {}, 'jobs': {'convert_train': Command({'parameters': {}, 'init': False, 'type': 'command', 'status': None, 'log_files': None, 'name': 'convert_train', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/eight-core-hadan326/code/Users/Notebooks/dogs_vs_cats_simple_designer_components', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f3bcce61b40>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'input_path': {'type': 'uri_file', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/af8800ab078e0eb8323765cc8d8d3ce3/train'}}, 'job_outputs': {}, 'inputs': {'input_path': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce61c60>}, 'outputs': {}, 'component': 'azureml_anonymous:5d772bb8-d827-4e75-8553-a556ab5b38dc', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': 'b23ae4eb-5a7f-438f-8777-de56ec08d6b3', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'swept': False}), 'convert_test': Command({'parameters': {}, 'init': False, 'type': 'command', 'status': None, 'log_files': None, 'name': 'convert_test', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/eight-core-hadan326/code/Users/Notebooks/dogs_vs_cats_simple_designer_components', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f3bcce618a0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'input_path': {'type': 'uri_file', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/9cada4c399036517126dc32a4d768c9a/test'}}, 'job_outputs': {}, 'inputs': {'input_path': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce61ae0>}, 'outputs': {}, 'component': 'azureml_anonymous:5d772bb8-d827-4e75-8553-a556ab5b38dc', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': 'ad282acb-bfdc-4918-91f3-9a657ac31ca6', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'swept': False}), 'init_image_transformation': Command({'parameters': {}, 'init': False, 'type': 'command', 'status': None, 'log_files': None, 'name': 'init_image_transformation', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/eight-core-hadan326/code/Users/Notebooks/dogs_vs_cats_simple_designer_components', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f3bcce627d0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'resize': 'True', 'size': '150', 'center_crop': 'False', 'pad': 'False', 'padding': '0', 'color_jitter': 'False', 'grayscale': 'False', 'random_resized_crop': 'False', 'random_crop': 'False', 'random_horizontal_flip': 'True', 'random_vertical_flip': 'False', 'random_rotation': 'False', 'random_affine': 'False', 'random_grayscale': 'False', 'random_perspective': 'False'}, 'job_outputs': {}, 'inputs': {'resize': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce62710>, 'size': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce61f00>, 'center_crop': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce61660>, 'pad': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce620b0>, 'padding': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce62170>, 'color_jitter': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce61f90>, 'grayscale': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce61fc0>, 'random_resized_crop': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce62320>, 'random_crop': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce616c0>, 'random_horizontal_flip': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce61990>, 'random_vertical_flip': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce619c0>, 'random_rotation': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce61750>, 'random_affine': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce61930>, 'random_grayscale': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce61780>, 'random_perspective': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce61720>}, 'outputs': {}, 'component': 'azureml_anonymous:c1ac0cfb-be8f-47a7-98e9-fce9b97b1090', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': '4ef26c51-9c06-4248-9909-aec061678132', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'swept': False}), 'apply_trans_on_train': Command({'parameters': {}, 'init': False, 'type': 'command', 'status': None, 'log_files': None, 'name': 'apply_trans_on_train', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/eight-core-hadan326/code/Users/Notebooks/dogs_vs_cats_simple_designer_components', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f3bcce622c0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'mode': 'For training', 'input_image_transform_path': '${{parent.jobs.init_image_transformation.outputs.output_path}}', 'input_image_dir_path': '${{parent.jobs.convert_train.outputs.output_path}}'}, 'job_outputs': {}, 'inputs': {'mode': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce62110>, 'input_image_transform_path': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce61570>, 'input_image_dir_path': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce62050>}, 'outputs': {}, 'component': 'azureml_anonymous:a619c3f4-968c-4558-bdff-20675ea649f0', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': '0100403a-7a59-462b-8e68-5044401d3bbe', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'swept': False}), 'apply_trans_on_val': Command({'parameters': {}, 'init': False, 'type': 'command', 'status': None, 'log_files': None, 'name': 'apply_trans_on_val', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/eight-core-hadan326/code/Users/Notebooks/dogs_vs_cats_simple_designer_components', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f3bcce62770>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'mode': 'For inference', 'input_image_transform_path': '${{parent.jobs.init_image_transformation.outputs.output_path}}', 'input_image_dir_path': '${{parent.jobs.convert_test.outputs.output_path}}'}, 'job_outputs': {}, 'inputs': {'mode': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce61ba0>, 'input_image_transform_path': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce61bd0>, 'input_image_dir_path': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce61c30>}, 'outputs': {}, 'component': 'azureml_anonymous:a619c3f4-968c-4558-bdff-20675ea649f0', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': '51ec4734-7a9a-4652-ae94-a83c9eb59d56', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'swept': False}), 'imagecnn_train_gpu': Command({'parameters': {}, 'init': False, 'type': 'command', 'status': None, 'log_files': None, 'name': 'imagecnn_train_gpu', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/eight-core-hadan326/code/Users/Notebooks/dogs_vs_cats_simple_designer_components', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f3bcce63700>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'data_backend': 'pytorch', 'arch': 'resnet50', 'model_config': 'classic', 'workers': '5', 'epochs': '4', 'batch_size': '16', 'optimizer_batch_size': '-1', 'lr': '0.1', 'lr_schedule': 'step', 'warmup': '0', 'label_smoothing': '0.0', 'mixup': '0.0', 'momentum': '0.9', 'weight_decay': '0.0001', 'print_freq': '10', 'resume': '', 'pretrained_weights': '', 'static_loss_scale': '1.0', 'prof': '-1', 'seed': '123', 'raport_file': 'experiment_raport.json', 'save_checkpoint_epochs': '2', 'train_data': '${{parent.jobs.apply_trans_on_train.outputs.output_path}}', 'valid_data': '${{parent.jobs.apply_trans_on_val.outputs.output_path}}'}, 'job_outputs': {}, 'inputs': {'data_backend': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce63610>, 'arch': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce63580>, 'model_config': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce63490>, 'workers': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce634c0>, 'epochs': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce633d0>, 'batch_size': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce63400>, 'optimizer_batch_size': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce63310>, 'lr': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce63340>, 'lr_schedule': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce63250>, 'warmup': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce63280>, 'label_smoothing': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce63190>, 'mixup': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce631c0>, 'momentum': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce630d0>, 'weight_decay': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce63100>, 'print_freq': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce63010>, 'resume': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce63040>, 'pretrained_weights': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce62f50>, 'static_loss_scale': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce62f80>, 'prof': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce62e90>, 'seed': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce62ec0>, 'raport_file': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce62dd0>, 'save_checkpoint_epochs': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce62e00>, 'train_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce62d10>, 'valid_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f3bcce62d40>}, 'outputs': {}, 'component': 'azureml_anonymous:7db85912-a75f-40db-8626-e981da75fac4', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': '380fb021-e937-4f92-8c46-271fd1cd0f7e', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': <azure.ai.ml.entities._job.distribution.MpiDistribution object at 0x7f3bcce63850>, 'environment_variables': {}, 'environment': None, 'resources': {'instance_count': 1}, 'queue_settings': None, 'swept': False})}, 'job_types': {'command': 6}, 'job_sources': {'REMOTE.WORKSPACE.COMPONENT': 6}, 'source_job_id': None}), 'type': 'pipeline', 'status': 'Preparing', 'log_files': None, 'name': 'busy_grass_frrqs42jd1', 'description': None, 'tags': {}, 'properties': {'azureml.DevPlatv2': 'true', 'azureml.DatasetAccessMode': 'Asset', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'MFE', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'True', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.enforceRerun': 'False', 'azureml.defaultComputeName': 'eight-core-hadan326', 'azureml.defaultDataStoreName': 'workspaceblobstore', 'azureml.pipelineComponent': 'pipelinerun'}, 'print_as_yaml': True, 'id': '/subscriptions/c6c6e76b-a64b-4a2e-87e4-4122626f39c7/resourceGroups/exjobb-t2304-11614/providers/Microsoft.MachineLearningServices/workspaces/ritko75_exjobb/jobs/busy_grass_frrqs42jd1', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/eight-core-hadan326/code/Users/Notebooks/dogs_vs_cats_simple_designer_components', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f3bcce62bc0>, 'serialize': <msrest.serialization.Serializer object at 0x7f3bcce62890>, 'display_name': 'cat_vs_dog_classifier', 'experiment_name': 'dogs_vs_cats_experiment2', 'compute': None, 'services': {'Tracking': <azure.ai.ml.entities._job.job_service.JobService object at 0x7f3bcce62ad0>, 'Studio': <azure.ai.ml.entities._job.job_service.JobService object at 0x7f3bcce62950>}, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None})",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>dogs_vs_cats_experiment2</td><td>busy_grass_frrqs42jd1</td><td>pipeline</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/busy_grass_frrqs42jd1?wsid=/subscriptions/c6c6e76b-a64b-4a2e-87e4-4122626f39c7/resourcegroups/exjobb-t2304-11614/workspaces/ritko75_exjobb&amp;tid=913f18ec-7f26-4c5f-a816-784fe9a58edd\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1684242400180
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# wait until the job completes\n",
        "ml_client.jobs.stream(pipeline_job.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: busy_grass_frrqs42jd1\nWeb View: https://ml.azure.com/runs/busy_grass_frrqs42jd1?wsid=/subscriptions/c6c6e76b-a64b-4a2e-87e4-4122626f39c7/resourcegroups/exjobb-t2304-11614/workspaces/ritko75_exjobb\n\nExecution Summary\n=================\nRunId: busy_grass_frrqs42jd1\nWeb View: https://ml.azure.com/runs/busy_grass_frrqs42jd1?wsid=/subscriptions/c6c6e76b-a64b-4a2e-87e4-4122626f39c7/resourcegroups/exjobb-t2304-11614/workspaces/ritko75_exjobb\n\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1684242598182
        }
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [
        {
          "file_id": "1gGstFRenv6QgcnT_JpGBrNO_849C419y",
          "timestamp": 1682324832663
        },
        {
          "file_id": "https://github.com/tensorflow/tfx/blob/master/docs/tutorials/tfx/penguin_simple.ipynb",
          "timestamp": 1680514822420
        }
      ]
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}